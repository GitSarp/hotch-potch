spring.application.name=kafkaDemo
server.port=8171
server.tomcat.uri-encoding=utf-8


#kafka
spring.kafka.bootstrap-servers=127.0.0.1:9092

#kafka-producer
spring.kafka.producer.retries=10
spring.kafka.producer.acks=1
#字节，在不超可用内存下，设置尽可能大可提高吞吐量（批量发送同一partition的消息以减少请求）
spring.kafka.producer.batch-size=16384
#最大1m
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.properties.linger.ms=1
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=com.example.kafkademo.kafka.KafkaEncoding

#kafka-consumer
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=1000
#无提交的offset时，从头开始消费，latest无提交offset时，消费新产生的该分区下的数据
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.properties.session.timeout=15000
spring.kafka.consumer.properties.concurrency =10
spring.kafka.consumer.group-id=testGroup
spring.kafka.consumer.group-id2=testGroup2
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=com.example.kafkademo.kafka.KafkaDecoding



